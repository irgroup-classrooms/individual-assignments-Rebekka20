# No. 2.:

# Documentation of Columns in the "lotr_scripts.csv" Dataset

## Unnamed: 0
**Description:**  
An automatically generated index that was added during the export of the file. This column is redundant and can be ignored or removed, as Pandas automatically creates its own index.

## char
**Description:**  
The name of the character from the Lord of the Rings films who is speaking the dialogue. Examples: "Frodo", "Gandalf".

## dialog
**Description:**  
The text of the dialogue spoken by a character. This column contains the main content for analyzing the dialogues.

## movie
**Description:**  
The title of the movie from which the dialogue originates. There are three possible values:  
- "The Fellowship of the Ring"  
- "The Two Towers"  
- "The Return of the King"

# No. 3. and 4.:

## "Dirty" Data Fields Identified and Subsequently Cleaned

**Approach**

1. Used pandas for cleaning.
2. Loaded the dataset.
3. Gained an overview of the dataset.
4. Removed round parentheses.
5. Showed 100 rows of the dataset.
6. Checked the dataset for missing values, so the number of missing values per column was displayed.
7. Replaced the missing value with an empty string, as there was only one missing value, I decided to replace it.
8. Checked if there were any NaN values in the 'dialog' column.
9. Replaced empty strings in the 'dialog' column, as there was still the missing value.
10. Checked if there were any remaining empty strings.
11. Checked if there were still any NaN values.
12. Removed the 'Unnamed: 0' column, which only represented the index.
13. Displayed the number of duplicated rows but decided not to delete them, as these are dialogues that can repeat.
14. Displayed all the duplicated rows.
15. Removed parentheses from the first and second columns
16. Removed special characters in the "dialog" column within the quotation marks.
17. Saved the cleaned data to a new CSV file

## Here is my Python code: 
```python

import pandas as pd
import re

file_path = r"C:\Users\Rebekka\OneDrive\Bilder\Desktop\DIS\3DataScience\DIS08DataModelling\Rebekka20\assignment\05\lotr_scripts.csv"

# CSV-Datei einlesen
df = pd.read_csv(file_path)

# Daten anzeigen
print(df.head())

# entfernt runde Klammern
df = df.replace(r"\(.*?\)", "", regex=True)

# zeigt 100 Zeilen des Datensatzes
print(df .head(100))

# Überprüfen auf fehlende Werte
print(df.isnull().sum())  # Zeigt die Anzahl der fehlenden Werte pro Spalte

# Fehlenden Wert mit leeren String aufgefüllt
df['dialog'] = df['dialog'].fillna('')

# Überprüfen, ob es NaN-Werte in der 'dialog' Spalte gibt
nan_dialogs = df[df['dialog'].isna()]
print("Zeilen mit NaN in 'dialog':", nan_dialogs)

# Leere Strings in der 'dialog' Spalte ersetzen
df['dialog'] = df['dialog'].replace('', 'Unbekannt')

# Überprüfen, ob es nun noch leere Strings gibt
empty_dialogs = df[df['dialog'] == '']
print("Zeilen mit leerem 'dialog' nach dem Ersetzen:", empty_dialogs)

# Überprüfen, ob noch NaN-Werte vorhanden sind
print(df.isnull().sum())  # Sollte 0 für 'dialog' zurückgeben

# Entfernt die 'Unnamed: 0' Spalte, die nur den Index darstellt
df = df.drop(columns=['Unnamed: 0']) 

# Gibt die Anzahl der doppelten Zeilen zurück
print(df.duplicated().sum()) 

# Zeige alle doppelten Zeilen an
duplicates = df[df.duplicated()]
print(duplicates)

print(df .head(100))

# Entferne Klammern aus der ersten und zweiten Spalte
df['char'] = df['char'].replace(r"[()]", "", regex=True)
df['dialog'] = df['dialog'].replace(r"[()]", "", regex=True)

# entfernt Sonderzeichen in der Spalte "dialog" innerhalb der ""
df['dialog'] = df['dialog'].apply(lambda x: re.sub(r'[^\w\s]', '', x))

# Bereinigte Daten in einer neuen CSV-Datei speichern
df.to_csv(r'C:\Users\Rebekka\OneDrive\Bilder\Desktop\DIS\3DataScience\DIS08DataModelling\Rebekka20\assignment\05\lotr_scripts_cleaned_.csv', index=False)

```
